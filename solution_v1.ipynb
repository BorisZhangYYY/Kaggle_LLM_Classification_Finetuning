{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d23016",
   "metadata": {},
   "source": [
    "# Kaggle: LLM Classification Finetuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e653a8",
   "metadata": {},
   "source": [
    "## 0. Environment and Dependencies\n",
    "\n",
    "Primary libraries used in this notebook:\n",
    "\n",
    "- `pandas`, `numpy`: data processing\n",
    "- `matplotlib`, `seaborn`: visualization\n",
    "- `scikit-learn`: dataset splitting and metrics (accuracy, log_loss)\n",
    "- `transformers`, `datasets`, `torch`: LLM fine-tuning (e.g., DistilBERT)\n",
    "\n",
    "Local environment (GPU setup):\n",
    "\n",
    "- PyTorch: 2.7.1+cu118\n",
    "- CUDA available: True\n",
    "- CUDA version: 11.8\n",
    "- GPU model: NVIDIA GeForce RTX 3050 Laptop GPU\n",
    "- Current device: 0\n",
    "\n",
    "Make sure all dependencies are installed before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20dfec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study_Project\\Kaggle_LLM_Classification_Finetuning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU model: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Current device: 0\n",
      "Transformers version: 5.2.0\n",
      "Python executable: d:\\Study_Project\\Kaggle_LLM_Classification_Finetuning\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU model: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"Python executable: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f14d5",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "- Train set: `Dataset/train.csv`\n",
    "- Test set: `Dataset/test.csv`\n",
    "\n",
    "Train set columns:\n",
    "\n",
    "- `id, model_a, model_b, prompt, response_a, response_b, winner_model_a, winner_model_b, winner_tie`\n",
    "\n",
    "Test set columns:\n",
    "\n",
    "- `id, prompt, response_a, response_b`\n",
    "\n",
    "Goal: given the prompt and two responses, predict which response users prefer (A / B / tie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0a3425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (57477, 9)\n",
      "Test shape: (3, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "3  [\"How can I create a test set for a very rare ...   \n",
       "4  [\"What is the best way to travel from Tel-Aviv...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "3  [\"Creating a test set for a very rare category...   \n",
       "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"Function calling is the process of invoking ...               0   \n",
       "3  [\"When building a classifier for a very rare c...               1   \n",
       "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  \n",
       "3               0           0  \n",
       "4               1           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = os.path.join(\"Dataset\", \"train.csv\")\n",
    "test_path = os.path.join(\"Dataset\", \"test.csv\")\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee0ef9",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Before training, visualize the dataset to understand its structure. Focus on:\n",
    "\n",
    "- Label distribution (winner)\n",
    "- Basic statistics and distributions of text lengths (prompt / response)\n",
    "- A few sample rows to understand the task format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148b9c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winner\n",
       "Model A    20064\n",
       "Model B    19652\n",
       "Tie        17761\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge winner columns into a single label\n",
    "def get_winner(row):\n",
    "    if row[\"winner_model_a\"] == 1:\n",
    "        return \"Model A\"\n",
    "    if row[\"winner_model_b\"] == 1:\n",
    "        return \"Model B\"\n",
    "    return \"Tie\"\n",
    "\n",
    "df_train[\"winner\"] = df_train.apply(get_winner, axis=1)\n",
    "\n",
    "df_train[\"winner\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5446e35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[\"len_prompt\"] = df_train[\"prompt\"].astype(str).apply(len)\n",
    "df_train[\"len_resp_a\"] = df_train[\"response_a\"].astype(str).apply(len)\n",
    "df_train[\"len_resp_b\"] = df_train[\"response_b\"].astype(str).apply(len)\n",
    "\n",
    "q_prompt = df_train[\"len_prompt\"].quantile(0.95)\n",
    "q_resp_a = df_train[\"len_resp_a\"].quantile(0.95)\n",
    "q_resp_b = df_train[\"len_resp_b\"].quantile(0.95)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "sns.histplot(df_train[\"len_prompt\"], bins=50, ax=axes[0])\n",
    "axes[0].set_title(\"Prompt Length (0-95% quantile)\")\n",
    "axes[0].set_xlim(0, q_prompt)\n",
    "\n",
    "sns.histplot(df_train[\"len_resp_a\"], bins=50, ax=axes[1])\n",
    "axes[1].set_title(\"Response A Length (0-95% quantile)\")\n",
    "axes[1].set_xlim(0, q_resp_a)\n",
    "\n",
    "sns.histplot(df_train[\"len_resp_b\"], bins=50, ax=axes[2])\n",
    "axes[2].set_title(\"Response B Length (0-95% quantile)\")\n",
    "axes[2].set_xlim(0, q_resp_b)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab2f2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>Model A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>Model B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>Tie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "\n",
       "                                          response_b   winner  \n",
       "0  [\"As an AI, I don't have personal beliefs or o...  Model A  \n",
       "1  [\"A marriage license and a marriage certificat...  Model B  \n",
       "2  [\"Function calling is the process of invoking ...      Tie  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[[\"prompt\", \"response_a\", \"response_b\", \"winner\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54368ac4",
   "metadata": {},
   "source": [
    "## 3. Model Choice and Principles\n",
    "\n",
    "This is a **text multi-class classification** task: given `(prompt, response_a, response_b)`, predict which response is preferred (or tie).\n",
    "\n",
    "This notebook uses **DistilBERT** as the base model:\n",
    "\n",
    "- DistilBERT is a distilled, smaller BERT with fewer parameters and faster inference, while preserving most semantic capability.\n",
    "- Pretraining learns general language representations; fine-tuning maps them to the preference classification task.\n",
    "- Model card and paper:\n",
    "  - https://huggingface.co/distilbert-base-uncased\n",
    "  - https://arxiv.org/abs/1910.01108\n",
    "\n",
    "### Input Construction Strategy\n",
    "\n",
    "We concatenate `(prompt, response_a, response_b)` into a single sequence so the model can compare both responses within one context window.\n",
    "\n",
    "```text\n",
    "Prompt: <prompt> \\n Response A: <response_a> \\n Response B: <response_b>\n",
    "```\n",
    "\n",
    "Why this works:\n",
    "- Self-attention aligns key information across segments, learning prompt-response alignment and A/B differences.\n",
    "- The classifier reads a single global representation (e.g., [CLS] or pooled embedding), effectively comparing all three segments.\n",
    "- A fixed template (Prompt / Response A / Response B) makes the input structure explicit and stable.\n",
    "\n",
    "The output layer is a 3-class classifier:\n",
    "- Class 0: Model A wins\n",
    "- Class 1: Model B wins\n",
    "- Class 2: Tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fab63fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    20064\n",
       "1    19652\n",
       "2    17761\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "label2id = {\"Model A\": 0, \"Model B\": 1, \"Tie\": 2}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "df_train[\"label\"] = df_train[\"winner\"].map(label2id)\n",
    "df_train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642ca8a4",
   "metadata": {},
   "source": [
    "## 4. Metrics and Loss Function\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "- For multi-class classification, the standard choice is **cross-entropy loss**.\n",
    "- In `transformers`, `AutoModelForSequenceClassification` automatically applies cross-entropy when `labels` are provided.\n",
    "\n",
    "### Metrics\n",
    "\n",
    "- **Accuracy**: correct predictions / total samples.\n",
    "- **Log Loss**: a Kaggle-standard metric that measures how close the predicted probability distribution is to the true labels (lower is better).\n",
    "\n",
    "In the Trainer, we compute both metrics via a custom `compute_metrics` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb6de4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 51729/51729 [00:18<00:00, 2788.23 examples/s]\n",
      "Map: 100%|| 5748/5748 [00:01<00:00, 3006.64 examples/s]\n",
      "Map: 100%|| 3/3 [00:00<00:00, 404.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    texts = [\n",
    "        f\"Prompt: {p} \\n Response A: {a} \\n Response B: {b}\"\n",
    "        for p, a, b in zip(examples[\"prompt\"], examples[\"response_a\"], examples[\"response_b\"])\n",
    "    ]\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    if \"label\" in examples:\n",
    "        tokenized[\"labels\"] = examples[\"label\"]\n",
    "    return tokenized\n",
    "\n",
    "# Split train/validation sets\n",
    "train_df, val_df = train_test_split(\n",
    "    df_train,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=df_train[\"label\"],\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(df_test.reset_index(drop=True))\n",
    "\n",
    "train_enc = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names,\n",
    ")\n",
    "val_enc = val_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=val_dataset.column_names,\n",
    ")\n",
    "test_enc = test_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=test_dataset.column_names,\n",
    ")\n",
    "\n",
    "train_enc.set_format(\"torch\")\n",
    "val_enc.set_format(\"torch\")\n",
    "test_enc.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aafeb82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    preds = probs.argmax(axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    try:\n",
    "        ll = log_loss(labels, probs)\n",
    "    except ValueError:\n",
    "        ll = float(\"nan\")\n",
    "    return {\"accuracy\": acc, \"log_loss\": ll}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a3c0cb",
   "metadata": {},
   "source": [
    "## 5. Model Building and Training\n",
    "\n",
    "We build a 3-class model with `AutoModelForSequenceClassification`:\n",
    "\n",
    "- `num_labels=3`\n",
    "- `id2label` / `label2id` map class IDs to readable labels.\n",
    "\n",
    "Key training parameters and what they do:\n",
    "- `learning_rate`: step size; too large causes instability, too small slows convergence. Typical range: 1e-5 to 5e-5.\n",
    "- `num_train_epochs`: number of full passes; higher can overfit. Monitor validation metrics as it increases.\n",
    "- `per_device_train_batch_size`: batch size per GPU; limited by VRAM. Use gradient accumulation to simulate larger batches.\n",
    "- `gradient_accumulation_steps`: accumulates gradients across steps; effective batch = batch_size  accumulation_steps.\n",
    "- `weight_decay`: regularization to reduce overfitting; commonly 0.01.\n",
    "- `fp16`: mixed precision for faster training and lower memory usage on GPUs.\n",
    "- `eval_strategy` / `save_strategy`: evaluation and checkpointing cadence; must match when `load_best_model_at_end=True`.\n",
    "- `logging_steps`: log interval for tracking loss.\n",
    "- `save_total_limit`: limits checkpoint count to save disk space.\n",
    "- `warmup_ratio` or `warmup_steps`: warms up the learning rate for stability.\n",
    "\n",
    "Tuning tips:\n",
    "- Start with fewer epochs and a smaller batch to validate the pipeline, then scale up.\n",
    "- If validation loss rises, reduce epochs or increase regularization.\n",
    "- When VRAM is limited, use gradient accumulation instead of a larger batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "524270e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|| 100/100 [00:00<00:00, 1074.20it/s, Materializing param=distilbert.transformer.layer.5.sa_layer_norm.weight]   \n",
      "\u001b[1mDistilBertForSequenceClassification LOAD REPORT\u001b[0m from: distilbert-base-uncased\n",
      "Key                     | Status     | \n",
      "------------------------+------------+-\n",
      "vocab_layer_norm.weight | UNEXPECTED | \n",
      "vocab_projector.bias    | UNEXPECTED | \n",
      "vocab_transform.bias    | UNEXPECTED | \n",
      "vocab_transform.weight  | UNEXPECTED | \n",
      "vocab_layer_norm.bias   | UNEXPECTED | \n",
      "classifier.weight       | MISSING    | \n",
      "pre_classifier.weight   | MISSING    | \n",
      "classifier.bias         | MISSING    | \n",
      "pre_classifier.bias     | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n",
      "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19401' max='19401' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19401/19401 2:59:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.105461</td>\n",
       "      <td>1.098064</td>\n",
       "      <td>0.340292</td>\n",
       "      <td>1.098070</td>\n",
       "      <td>33.297700</td>\n",
       "      <td>172.625000</td>\n",
       "      <td>10.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.096436</td>\n",
       "      <td>1.098012</td>\n",
       "      <td>0.341162</td>\n",
       "      <td>1.098010</td>\n",
       "      <td>34.137100</td>\n",
       "      <td>168.380000</td>\n",
       "      <td>10.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.096296</td>\n",
       "      <td>1.096339</td>\n",
       "      <td>0.342728</td>\n",
       "      <td>1.096333</td>\n",
       "      <td>34.009700</td>\n",
       "      <td>169.010000</td>\n",
       "      <td>10.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.096395</td>\n",
       "      <td>1.096681</td>\n",
       "      <td>0.352992</td>\n",
       "      <td>1.096683</td>\n",
       "      <td>33.513800</td>\n",
       "      <td>171.511000</td>\n",
       "      <td>10.742000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.089233</td>\n",
       "      <td>1.096474</td>\n",
       "      <td>0.355428</td>\n",
       "      <td>1.096476</td>\n",
       "      <td>33.566500</td>\n",
       "      <td>171.242000</td>\n",
       "      <td>10.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.091576</td>\n",
       "      <td>1.091262</td>\n",
       "      <td>0.372999</td>\n",
       "      <td>1.091259</td>\n",
       "      <td>33.233800</td>\n",
       "      <td>172.956000</td>\n",
       "      <td>10.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.095829</td>\n",
       "      <td>1.098621</td>\n",
       "      <td>0.357342</td>\n",
       "      <td>1.098625</td>\n",
       "      <td>33.390500</td>\n",
       "      <td>172.145000</td>\n",
       "      <td>10.782000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.111891</td>\n",
       "      <td>1.090329</td>\n",
       "      <td>0.370912</td>\n",
       "      <td>1.090334</td>\n",
       "      <td>34.071300</td>\n",
       "      <td>168.705000</td>\n",
       "      <td>10.566000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.095653</td>\n",
       "      <td>1.088914</td>\n",
       "      <td>0.372129</td>\n",
       "      <td>1.088917</td>\n",
       "      <td>34.411700</td>\n",
       "      <td>167.036000</td>\n",
       "      <td>10.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.095322</td>\n",
       "      <td>1.091418</td>\n",
       "      <td>0.362213</td>\n",
       "      <td>1.091414</td>\n",
       "      <td>34.631800</td>\n",
       "      <td>165.975000</td>\n",
       "      <td>10.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.093452</td>\n",
       "      <td>1.089131</td>\n",
       "      <td>0.370042</td>\n",
       "      <td>1.089138</td>\n",
       "      <td>33.622300</td>\n",
       "      <td>170.958000</td>\n",
       "      <td>10.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.085341</td>\n",
       "      <td>1.089612</td>\n",
       "      <td>0.372825</td>\n",
       "      <td>1.089614</td>\n",
       "      <td>34.249300</td>\n",
       "      <td>167.828000</td>\n",
       "      <td>10.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.093369</td>\n",
       "      <td>1.095570</td>\n",
       "      <td>0.371608</td>\n",
       "      <td>1.095566</td>\n",
       "      <td>33.331500</td>\n",
       "      <td>172.450000</td>\n",
       "      <td>10.801000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.112126</td>\n",
       "      <td>1.088269</td>\n",
       "      <td>0.375087</td>\n",
       "      <td>1.088275</td>\n",
       "      <td>33.211700</td>\n",
       "      <td>173.072000</td>\n",
       "      <td>10.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.094502</td>\n",
       "      <td>1.090554</td>\n",
       "      <td>0.370042</td>\n",
       "      <td>1.090555</td>\n",
       "      <td>33.181700</td>\n",
       "      <td>173.228000</td>\n",
       "      <td>10.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.097885</td>\n",
       "      <td>1.089479</td>\n",
       "      <td>0.373173</td>\n",
       "      <td>1.089479</td>\n",
       "      <td>33.427300</td>\n",
       "      <td>171.955000</td>\n",
       "      <td>10.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.095455</td>\n",
       "      <td>1.089305</td>\n",
       "      <td>0.378740</td>\n",
       "      <td>1.089310</td>\n",
       "      <td>33.300600</td>\n",
       "      <td>172.609000</td>\n",
       "      <td>10.811000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.085880</td>\n",
       "      <td>1.088742</td>\n",
       "      <td>0.376305</td>\n",
       "      <td>1.088736</td>\n",
       "      <td>33.203000</td>\n",
       "      <td>173.117000</td>\n",
       "      <td>10.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.098353</td>\n",
       "      <td>1.090223</td>\n",
       "      <td>0.370390</td>\n",
       "      <td>1.090220</td>\n",
       "      <td>33.246300</td>\n",
       "      <td>172.891000</td>\n",
       "      <td>10.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.076019</td>\n",
       "      <td>1.096142</td>\n",
       "      <td>0.366388</td>\n",
       "      <td>1.096147</td>\n",
       "      <td>33.251500</td>\n",
       "      <td>172.864000</td>\n",
       "      <td>10.827000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.075677</td>\n",
       "      <td>1.092874</td>\n",
       "      <td>0.369520</td>\n",
       "      <td>1.092881</td>\n",
       "      <td>33.425200</td>\n",
       "      <td>171.966000</td>\n",
       "      <td>10.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.076584</td>\n",
       "      <td>1.084241</td>\n",
       "      <td>0.376305</td>\n",
       "      <td>1.084237</td>\n",
       "      <td>35.153100</td>\n",
       "      <td>163.513000</td>\n",
       "      <td>10.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.091331</td>\n",
       "      <td>1.109427</td>\n",
       "      <td>0.375435</td>\n",
       "      <td>1.109426</td>\n",
       "      <td>33.764300</td>\n",
       "      <td>170.239000</td>\n",
       "      <td>10.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.082910</td>\n",
       "      <td>1.088256</td>\n",
       "      <td>0.380654</td>\n",
       "      <td>1.088261</td>\n",
       "      <td>33.271700</td>\n",
       "      <td>172.760000</td>\n",
       "      <td>10.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.111061</td>\n",
       "      <td>1.092431</td>\n",
       "      <td>0.378045</td>\n",
       "      <td>1.092432</td>\n",
       "      <td>33.227000</td>\n",
       "      <td>172.992000</td>\n",
       "      <td>10.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.088152</td>\n",
       "      <td>1.085896</td>\n",
       "      <td>0.375087</td>\n",
       "      <td>1.085896</td>\n",
       "      <td>33.358700</td>\n",
       "      <td>172.309000</td>\n",
       "      <td>10.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.084284</td>\n",
       "      <td>1.088666</td>\n",
       "      <td>0.367258</td>\n",
       "      <td>1.088669</td>\n",
       "      <td>33.237900</td>\n",
       "      <td>172.935000</td>\n",
       "      <td>10.831000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.102223</td>\n",
       "      <td>1.084851</td>\n",
       "      <td>0.375957</td>\n",
       "      <td>1.084846</td>\n",
       "      <td>33.328100</td>\n",
       "      <td>172.467000</td>\n",
       "      <td>10.802000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.095587</td>\n",
       "      <td>1.084181</td>\n",
       "      <td>0.385177</td>\n",
       "      <td>1.084182</td>\n",
       "      <td>33.194200</td>\n",
       "      <td>173.163000</td>\n",
       "      <td>10.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.088757</td>\n",
       "      <td>1.088429</td>\n",
       "      <td>0.379262</td>\n",
       "      <td>1.088431</td>\n",
       "      <td>33.335600</td>\n",
       "      <td>172.428000</td>\n",
       "      <td>10.799000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.088602</td>\n",
       "      <td>1.085459</td>\n",
       "      <td>0.382046</td>\n",
       "      <td>1.085456</td>\n",
       "      <td>34.339600</td>\n",
       "      <td>167.387000</td>\n",
       "      <td>10.484000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.088489</td>\n",
       "      <td>1.084033</td>\n",
       "      <td>0.379958</td>\n",
       "      <td>1.084034</td>\n",
       "      <td>33.855900</td>\n",
       "      <td>169.779000</td>\n",
       "      <td>10.633000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.088956</td>\n",
       "      <td>1.085627</td>\n",
       "      <td>0.380480</td>\n",
       "      <td>1.085626</td>\n",
       "      <td>33.738200</td>\n",
       "      <td>170.371000</td>\n",
       "      <td>10.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.093181</td>\n",
       "      <td>1.082374</td>\n",
       "      <td>0.391788</td>\n",
       "      <td>1.082380</td>\n",
       "      <td>33.702600</td>\n",
       "      <td>170.551000</td>\n",
       "      <td>10.682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.101555</td>\n",
       "      <td>1.085562</td>\n",
       "      <td>0.374391</td>\n",
       "      <td>1.085559</td>\n",
       "      <td>33.659100</td>\n",
       "      <td>170.771000</td>\n",
       "      <td>10.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.095236</td>\n",
       "      <td>1.087315</td>\n",
       "      <td>0.377523</td>\n",
       "      <td>1.087315</td>\n",
       "      <td>33.735200</td>\n",
       "      <td>170.386000</td>\n",
       "      <td>10.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>1.078054</td>\n",
       "      <td>1.106951</td>\n",
       "      <td>0.360125</td>\n",
       "      <td>1.106947</td>\n",
       "      <td>33.936900</td>\n",
       "      <td>169.373000</td>\n",
       "      <td>10.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.094647</td>\n",
       "      <td>1.083737</td>\n",
       "      <td>0.385351</td>\n",
       "      <td>1.083736</td>\n",
       "      <td>33.919000</td>\n",
       "      <td>169.462000</td>\n",
       "      <td>10.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.099465</td>\n",
       "      <td>1.083245</td>\n",
       "      <td>0.379784</td>\n",
       "      <td>1.083243</td>\n",
       "      <td>33.795000</td>\n",
       "      <td>170.085000</td>\n",
       "      <td>10.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.078224</td>\n",
       "      <td>1.079476</td>\n",
       "      <td>0.383438</td>\n",
       "      <td>1.079478</td>\n",
       "      <td>33.706000</td>\n",
       "      <td>170.534000</td>\n",
       "      <td>10.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>1.077952</td>\n",
       "      <td>1.079552</td>\n",
       "      <td>0.403271</td>\n",
       "      <td>1.079550</td>\n",
       "      <td>33.656500</td>\n",
       "      <td>170.784000</td>\n",
       "      <td>10.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.093651</td>\n",
       "      <td>1.088445</td>\n",
       "      <td>0.385177</td>\n",
       "      <td>1.088451</td>\n",
       "      <td>33.886700</td>\n",
       "      <td>169.624000</td>\n",
       "      <td>10.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>1.089207</td>\n",
       "      <td>1.084605</td>\n",
       "      <td>0.381698</td>\n",
       "      <td>1.084605</td>\n",
       "      <td>33.781700</td>\n",
       "      <td>170.151000</td>\n",
       "      <td>10.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.059047</td>\n",
       "      <td>1.085078</td>\n",
       "      <td>0.388657</td>\n",
       "      <td>1.085075</td>\n",
       "      <td>33.763600</td>\n",
       "      <td>170.242000</td>\n",
       "      <td>10.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.079954</td>\n",
       "      <td>1.084551</td>\n",
       "      <td>0.380654</td>\n",
       "      <td>1.084551</td>\n",
       "      <td>33.904700</td>\n",
       "      <td>169.534000</td>\n",
       "      <td>10.618000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>1.092273</td>\n",
       "      <td>1.084545</td>\n",
       "      <td>0.387961</td>\n",
       "      <td>1.084553</td>\n",
       "      <td>33.803000</td>\n",
       "      <td>170.044000</td>\n",
       "      <td>10.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>1.070151</td>\n",
       "      <td>1.083144</td>\n",
       "      <td>0.398573</td>\n",
       "      <td>1.083148</td>\n",
       "      <td>33.698400</td>\n",
       "      <td>170.572000</td>\n",
       "      <td>10.683000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.077407</td>\n",
       "      <td>1.080443</td>\n",
       "      <td>0.408316</td>\n",
       "      <td>1.080443</td>\n",
       "      <td>33.641500</td>\n",
       "      <td>170.860000</td>\n",
       "      <td>10.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>1.092378</td>\n",
       "      <td>1.081537</td>\n",
       "      <td>0.385699</td>\n",
       "      <td>1.081539</td>\n",
       "      <td>34.157600</td>\n",
       "      <td>168.279000</td>\n",
       "      <td>10.539000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.087629</td>\n",
       "      <td>1.089883</td>\n",
       "      <td>0.376653</td>\n",
       "      <td>1.089883</td>\n",
       "      <td>33.802500</td>\n",
       "      <td>170.047000</td>\n",
       "      <td>10.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>1.074046</td>\n",
       "      <td>1.077431</td>\n",
       "      <td>0.412665</td>\n",
       "      <td>1.077429</td>\n",
       "      <td>33.936800</td>\n",
       "      <td>169.374000</td>\n",
       "      <td>10.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>1.101137</td>\n",
       "      <td>1.073924</td>\n",
       "      <td>0.405706</td>\n",
       "      <td>1.073924</td>\n",
       "      <td>33.747500</td>\n",
       "      <td>170.324000</td>\n",
       "      <td>10.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>1.061246</td>\n",
       "      <td>1.075623</td>\n",
       "      <td>0.394050</td>\n",
       "      <td>1.075623</td>\n",
       "      <td>33.787700</td>\n",
       "      <td>170.121000</td>\n",
       "      <td>10.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>1.085526</td>\n",
       "      <td>1.082717</td>\n",
       "      <td>0.402749</td>\n",
       "      <td>1.082718</td>\n",
       "      <td>33.889000</td>\n",
       "      <td>169.613000</td>\n",
       "      <td>10.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.082326</td>\n",
       "      <td>1.069372</td>\n",
       "      <td>0.416319</td>\n",
       "      <td>1.069367</td>\n",
       "      <td>33.947900</td>\n",
       "      <td>169.318000</td>\n",
       "      <td>10.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>1.092941</td>\n",
       "      <td>1.078168</td>\n",
       "      <td>0.399269</td>\n",
       "      <td>1.078168</td>\n",
       "      <td>34.611000</td>\n",
       "      <td>166.074000</td>\n",
       "      <td>10.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>1.070871</td>\n",
       "      <td>1.072646</td>\n",
       "      <td>0.412143</td>\n",
       "      <td>1.072647</td>\n",
       "      <td>34.668400</td>\n",
       "      <td>165.799000</td>\n",
       "      <td>10.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>1.069173</td>\n",
       "      <td>1.073754</td>\n",
       "      <td>0.414579</td>\n",
       "      <td>1.073756</td>\n",
       "      <td>36.254600</td>\n",
       "      <td>158.545000</td>\n",
       "      <td>9.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>1.096169</td>\n",
       "      <td>1.070897</td>\n",
       "      <td>0.421364</td>\n",
       "      <td>1.070898</td>\n",
       "      <td>36.006200</td>\n",
       "      <td>159.639000</td>\n",
       "      <td>9.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.082434</td>\n",
       "      <td>1.070209</td>\n",
       "      <td>0.421886</td>\n",
       "      <td>1.070208</td>\n",
       "      <td>36.924200</td>\n",
       "      <td>155.670000</td>\n",
       "      <td>9.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>1.063508</td>\n",
       "      <td>1.076525</td>\n",
       "      <td>0.424669</td>\n",
       "      <td>1.076525</td>\n",
       "      <td>36.803500</td>\n",
       "      <td>156.181000</td>\n",
       "      <td>9.782000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>1.078578</td>\n",
       "      <td>1.070327</td>\n",
       "      <td>0.418754</td>\n",
       "      <td>1.070328</td>\n",
       "      <td>36.470100</td>\n",
       "      <td>157.609000</td>\n",
       "      <td>9.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>1.077782</td>\n",
       "      <td>1.068451</td>\n",
       "      <td>0.425539</td>\n",
       "      <td>1.068446</td>\n",
       "      <td>37.936900</td>\n",
       "      <td>151.515000</td>\n",
       "      <td>9.489000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>1.045014</td>\n",
       "      <td>1.086763</td>\n",
       "      <td>0.414405</td>\n",
       "      <td>1.086763</td>\n",
       "      <td>35.744100</td>\n",
       "      <td>160.810000</td>\n",
       "      <td>10.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.092518</td>\n",
       "      <td>1.072783</td>\n",
       "      <td>0.411447</td>\n",
       "      <td>1.072784</td>\n",
       "      <td>35.187200</td>\n",
       "      <td>163.355000</td>\n",
       "      <td>10.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>1.058226</td>\n",
       "      <td>1.060214</td>\n",
       "      <td>0.434934</td>\n",
       "      <td>1.060211</td>\n",
       "      <td>34.062200</td>\n",
       "      <td>168.750000</td>\n",
       "      <td>10.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>1.048904</td>\n",
       "      <td>1.059927</td>\n",
       "      <td>0.435282</td>\n",
       "      <td>1.059927</td>\n",
       "      <td>33.894500</td>\n",
       "      <td>169.585000</td>\n",
       "      <td>10.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>1.055102</td>\n",
       "      <td>1.061190</td>\n",
       "      <td>0.432672</td>\n",
       "      <td>1.061188</td>\n",
       "      <td>33.993100</td>\n",
       "      <td>169.093000</td>\n",
       "      <td>10.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>1.038495</td>\n",
       "      <td>1.065264</td>\n",
       "      <td>0.441545</td>\n",
       "      <td>1.065256</td>\n",
       "      <td>33.869700</td>\n",
       "      <td>169.709000</td>\n",
       "      <td>10.629000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.062153</td>\n",
       "      <td>1.078850</td>\n",
       "      <td>0.410578</td>\n",
       "      <td>1.078846</td>\n",
       "      <td>33.941500</td>\n",
       "      <td>169.350000</td>\n",
       "      <td>10.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>1.068302</td>\n",
       "      <td>1.061614</td>\n",
       "      <td>0.438065</td>\n",
       "      <td>1.061616</td>\n",
       "      <td>33.942500</td>\n",
       "      <td>169.345000</td>\n",
       "      <td>10.606000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>1.034619</td>\n",
       "      <td>1.064283</td>\n",
       "      <td>0.438761</td>\n",
       "      <td>1.064286</td>\n",
       "      <td>33.871400</td>\n",
       "      <td>169.701000</td>\n",
       "      <td>10.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>1.063241</td>\n",
       "      <td>1.055041</td>\n",
       "      <td>0.444154</td>\n",
       "      <td>1.055042</td>\n",
       "      <td>33.689400</td>\n",
       "      <td>170.617000</td>\n",
       "      <td>10.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>1.053807</td>\n",
       "      <td>1.064051</td>\n",
       "      <td>0.437370</td>\n",
       "      <td>1.064052</td>\n",
       "      <td>33.638900</td>\n",
       "      <td>170.874000</td>\n",
       "      <td>10.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.026725</td>\n",
       "      <td>1.066542</td>\n",
       "      <td>0.435456</td>\n",
       "      <td>1.066541</td>\n",
       "      <td>33.948200</td>\n",
       "      <td>169.317000</td>\n",
       "      <td>10.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>1.065190</td>\n",
       "      <td>1.054087</td>\n",
       "      <td>0.439283</td>\n",
       "      <td>1.054091</td>\n",
       "      <td>33.836300</td>\n",
       "      <td>169.877000</td>\n",
       "      <td>10.639000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>1.046961</td>\n",
       "      <td>1.065513</td>\n",
       "      <td>0.438761</td>\n",
       "      <td>1.065509</td>\n",
       "      <td>33.755700</td>\n",
       "      <td>170.282000</td>\n",
       "      <td>10.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>1.035774</td>\n",
       "      <td>1.053104</td>\n",
       "      <td>0.445198</td>\n",
       "      <td>1.053104</td>\n",
       "      <td>33.739800</td>\n",
       "      <td>170.362000</td>\n",
       "      <td>10.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>1.014397</td>\n",
       "      <td>1.075819</td>\n",
       "      <td>0.435108</td>\n",
       "      <td>1.075817</td>\n",
       "      <td>33.678100</td>\n",
       "      <td>170.675000</td>\n",
       "      <td>10.689000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.073896</td>\n",
       "      <td>1.082348</td>\n",
       "      <td>0.410056</td>\n",
       "      <td>1.082348</td>\n",
       "      <td>33.616300</td>\n",
       "      <td>170.989000</td>\n",
       "      <td>10.709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>1.048803</td>\n",
       "      <td>1.065205</td>\n",
       "      <td>0.438413</td>\n",
       "      <td>1.065207</td>\n",
       "      <td>33.875900</td>\n",
       "      <td>169.678000</td>\n",
       "      <td>10.627000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>1.047863</td>\n",
       "      <td>1.061575</td>\n",
       "      <td>0.443633</td>\n",
       "      <td>1.061580</td>\n",
       "      <td>33.697000</td>\n",
       "      <td>170.579000</td>\n",
       "      <td>10.683000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>1.028809</td>\n",
       "      <td>1.058227</td>\n",
       "      <td>0.439631</td>\n",
       "      <td>1.058224</td>\n",
       "      <td>33.752400</td>\n",
       "      <td>170.299000</td>\n",
       "      <td>10.666000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>1.062120</td>\n",
       "      <td>1.065681</td>\n",
       "      <td>0.425365</td>\n",
       "      <td>1.065676</td>\n",
       "      <td>33.792000</td>\n",
       "      <td>170.099000</td>\n",
       "      <td>10.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.035220</td>\n",
       "      <td>1.077175</td>\n",
       "      <td>0.435108</td>\n",
       "      <td>1.077172</td>\n",
       "      <td>33.657200</td>\n",
       "      <td>170.781000</td>\n",
       "      <td>10.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>1.043499</td>\n",
       "      <td>1.065917</td>\n",
       "      <td>0.438935</td>\n",
       "      <td>1.065918</td>\n",
       "      <td>33.883900</td>\n",
       "      <td>169.638000</td>\n",
       "      <td>10.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>1.064014</td>\n",
       "      <td>1.059098</td>\n",
       "      <td>0.437543</td>\n",
       "      <td>1.059098</td>\n",
       "      <td>33.770200</td>\n",
       "      <td>170.209000</td>\n",
       "      <td>10.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>1.052096</td>\n",
       "      <td>1.060760</td>\n",
       "      <td>0.441893</td>\n",
       "      <td>1.060760</td>\n",
       "      <td>34.042700</td>\n",
       "      <td>168.847000</td>\n",
       "      <td>10.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>1.042185</td>\n",
       "      <td>1.057990</td>\n",
       "      <td>0.438065</td>\n",
       "      <td>1.057989</td>\n",
       "      <td>34.043100</td>\n",
       "      <td>168.845000</td>\n",
       "      <td>10.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.001648</td>\n",
       "      <td>1.075886</td>\n",
       "      <td>0.441371</td>\n",
       "      <td>1.075881</td>\n",
       "      <td>34.950500</td>\n",
       "      <td>164.461000</td>\n",
       "      <td>10.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>1.065234</td>\n",
       "      <td>1.059583</td>\n",
       "      <td>0.442241</td>\n",
       "      <td>1.059582</td>\n",
       "      <td>36.276200</td>\n",
       "      <td>158.451000</td>\n",
       "      <td>9.924000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>1.023068</td>\n",
       "      <td>1.052938</td>\n",
       "      <td>0.446590</td>\n",
       "      <td>1.052938</td>\n",
       "      <td>36.839500</td>\n",
       "      <td>156.028000</td>\n",
       "      <td>9.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>1.040657</td>\n",
       "      <td>1.062616</td>\n",
       "      <td>0.441023</td>\n",
       "      <td>1.062617</td>\n",
       "      <td>35.778700</td>\n",
       "      <td>160.654000</td>\n",
       "      <td>10.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>1.052171</td>\n",
       "      <td>1.047673</td>\n",
       "      <td>0.451113</td>\n",
       "      <td>1.047671</td>\n",
       "      <td>35.567100</td>\n",
       "      <td>161.610000</td>\n",
       "      <td>10.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.035994</td>\n",
       "      <td>1.061749</td>\n",
       "      <td>0.448504</td>\n",
       "      <td>1.061749</td>\n",
       "      <td>36.409200</td>\n",
       "      <td>157.872000</td>\n",
       "      <td>9.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>1.051963</td>\n",
       "      <td>1.049228</td>\n",
       "      <td>0.446416</td>\n",
       "      <td>1.049229</td>\n",
       "      <td>38.875100</td>\n",
       "      <td>147.858000</td>\n",
       "      <td>9.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>1.045204</td>\n",
       "      <td>1.055079</td>\n",
       "      <td>0.447286</td>\n",
       "      <td>1.055078</td>\n",
       "      <td>38.839600</td>\n",
       "      <td>147.993000</td>\n",
       "      <td>9.269000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>1.024810</td>\n",
       "      <td>1.055881</td>\n",
       "      <td>0.447112</td>\n",
       "      <td>1.055880</td>\n",
       "      <td>39.105500</td>\n",
       "      <td>146.987000</td>\n",
       "      <td>9.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>1.034614</td>\n",
       "      <td>1.053442</td>\n",
       "      <td>0.447634</td>\n",
       "      <td>1.053437</td>\n",
       "      <td>38.769200</td>\n",
       "      <td>148.262000</td>\n",
       "      <td>9.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.061431</td>\n",
       "      <td>1.058459</td>\n",
       "      <td>0.439631</td>\n",
       "      <td>1.058456</td>\n",
       "      <td>35.345800</td>\n",
       "      <td>162.622000</td>\n",
       "      <td>10.185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>1.035547</td>\n",
       "      <td>1.056018</td>\n",
       "      <td>0.447634</td>\n",
       "      <td>1.056014</td>\n",
       "      <td>35.356200</td>\n",
       "      <td>162.574000</td>\n",
       "      <td>10.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>1.014558</td>\n",
       "      <td>1.055159</td>\n",
       "      <td>0.446242</td>\n",
       "      <td>1.055163</td>\n",
       "      <td>34.605500</td>\n",
       "      <td>166.101000</td>\n",
       "      <td>10.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>1.026502</td>\n",
       "      <td>1.068997</td>\n",
       "      <td>0.431802</td>\n",
       "      <td>1.069004</td>\n",
       "      <td>34.863900</td>\n",
       "      <td>164.870000</td>\n",
       "      <td>10.326000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>1.083860</td>\n",
       "      <td>1.046535</td>\n",
       "      <td>0.449896</td>\n",
       "      <td>1.046535</td>\n",
       "      <td>33.996900</td>\n",
       "      <td>169.074000</td>\n",
       "      <td>10.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.014275</td>\n",
       "      <td>1.054051</td>\n",
       "      <td>0.444328</td>\n",
       "      <td>1.054051</td>\n",
       "      <td>34.485600</td>\n",
       "      <td>166.678000</td>\n",
       "      <td>10.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>1.063583</td>\n",
       "      <td>1.051171</td>\n",
       "      <td>0.444328</td>\n",
       "      <td>1.051168</td>\n",
       "      <td>37.703800</td>\n",
       "      <td>152.451000</td>\n",
       "      <td>9.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>1.050750</td>\n",
       "      <td>1.051821</td>\n",
       "      <td>0.442067</td>\n",
       "      <td>1.051821</td>\n",
       "      <td>36.198600</td>\n",
       "      <td>158.791000</td>\n",
       "      <td>9.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>1.062222</td>\n",
       "      <td>1.048324</td>\n",
       "      <td>0.447634</td>\n",
       "      <td>1.048323</td>\n",
       "      <td>36.630800</td>\n",
       "      <td>156.917000</td>\n",
       "      <td>9.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>1.033965</td>\n",
       "      <td>1.052799</td>\n",
       "      <td>0.442067</td>\n",
       "      <td>1.052799</td>\n",
       "      <td>34.697000</td>\n",
       "      <td>165.663000</td>\n",
       "      <td>10.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.070276</td>\n",
       "      <td>1.060240</td>\n",
       "      <td>0.431976</td>\n",
       "      <td>1.060238</td>\n",
       "      <td>35.208100</td>\n",
       "      <td>163.258000</td>\n",
       "      <td>10.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>1.027646</td>\n",
       "      <td>1.049383</td>\n",
       "      <td>0.448504</td>\n",
       "      <td>1.049382</td>\n",
       "      <td>35.296800</td>\n",
       "      <td>162.848000</td>\n",
       "      <td>10.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>1.064734</td>\n",
       "      <td>1.050345</td>\n",
       "      <td>0.442241</td>\n",
       "      <td>1.050346</td>\n",
       "      <td>35.606200</td>\n",
       "      <td>161.433000</td>\n",
       "      <td>10.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>1.046581</td>\n",
       "      <td>1.045074</td>\n",
       "      <td>0.456333</td>\n",
       "      <td>1.045072</td>\n",
       "      <td>36.115600</td>\n",
       "      <td>159.156000</td>\n",
       "      <td>9.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>1.040423</td>\n",
       "      <td>1.050885</td>\n",
       "      <td>0.452679</td>\n",
       "      <td>1.050888</td>\n",
       "      <td>34.948400</td>\n",
       "      <td>164.471000</td>\n",
       "      <td>10.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.030280</td>\n",
       "      <td>1.054284</td>\n",
       "      <td>0.448852</td>\n",
       "      <td>1.054282</td>\n",
       "      <td>34.703600</td>\n",
       "      <td>165.631000</td>\n",
       "      <td>10.374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>1.021339</td>\n",
       "      <td>1.057971</td>\n",
       "      <td>0.443633</td>\n",
       "      <td>1.057973</td>\n",
       "      <td>34.626500</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>10.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>1.036616</td>\n",
       "      <td>1.048190</td>\n",
       "      <td>0.448156</td>\n",
       "      <td>1.048190</td>\n",
       "      <td>34.708900</td>\n",
       "      <td>165.606000</td>\n",
       "      <td>10.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>1.037904</td>\n",
       "      <td>1.052361</td>\n",
       "      <td>0.454419</td>\n",
       "      <td>1.052362</td>\n",
       "      <td>34.652100</td>\n",
       "      <td>165.877000</td>\n",
       "      <td>10.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>1.038423</td>\n",
       "      <td>1.045953</td>\n",
       "      <td>0.451461</td>\n",
       "      <td>1.045951</td>\n",
       "      <td>34.962200</td>\n",
       "      <td>164.406000</td>\n",
       "      <td>10.297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.996881</td>\n",
       "      <td>1.057751</td>\n",
       "      <td>0.454071</td>\n",
       "      <td>1.057753</td>\n",
       "      <td>34.593200</td>\n",
       "      <td>166.160000</td>\n",
       "      <td>10.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>1.034514</td>\n",
       "      <td>1.050982</td>\n",
       "      <td>0.449722</td>\n",
       "      <td>1.050982</td>\n",
       "      <td>34.732800</td>\n",
       "      <td>165.492000</td>\n",
       "      <td>10.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>1.059756</td>\n",
       "      <td>1.043642</td>\n",
       "      <td>0.459116</td>\n",
       "      <td>1.043638</td>\n",
       "      <td>34.828800</td>\n",
       "      <td>165.036000</td>\n",
       "      <td>10.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>1.026480</td>\n",
       "      <td>1.047582</td>\n",
       "      <td>0.453897</td>\n",
       "      <td>1.047586</td>\n",
       "      <td>34.619200</td>\n",
       "      <td>166.035000</td>\n",
       "      <td>10.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>1.006402</td>\n",
       "      <td>1.051753</td>\n",
       "      <td>0.459116</td>\n",
       "      <td>1.051757</td>\n",
       "      <td>34.614400</td>\n",
       "      <td>166.058000</td>\n",
       "      <td>10.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>1.055666</td>\n",
       "      <td>1.041286</td>\n",
       "      <td>0.459116</td>\n",
       "      <td>1.041286</td>\n",
       "      <td>34.715400</td>\n",
       "      <td>165.575000</td>\n",
       "      <td>10.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>1.043479</td>\n",
       "      <td>1.041709</td>\n",
       "      <td>0.454767</td>\n",
       "      <td>1.041703</td>\n",
       "      <td>34.604600</td>\n",
       "      <td>166.105000</td>\n",
       "      <td>10.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>1.037037</td>\n",
       "      <td>1.045742</td>\n",
       "      <td>0.458072</td>\n",
       "      <td>1.045742</td>\n",
       "      <td>34.666100</td>\n",
       "      <td>165.811000</td>\n",
       "      <td>10.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>1.042020</td>\n",
       "      <td>1.043435</td>\n",
       "      <td>0.459812</td>\n",
       "      <td>1.043441</td>\n",
       "      <td>34.570500</td>\n",
       "      <td>166.269000</td>\n",
       "      <td>10.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>1.036891</td>\n",
       "      <td>1.045211</td>\n",
       "      <td>0.449722</td>\n",
       "      <td>1.045209</td>\n",
       "      <td>35.098200</td>\n",
       "      <td>163.769000</td>\n",
       "      <td>10.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.018202</td>\n",
       "      <td>1.046182</td>\n",
       "      <td>0.457376</td>\n",
       "      <td>1.046181</td>\n",
       "      <td>33.651500</td>\n",
       "      <td>170.810000</td>\n",
       "      <td>10.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>1.011346</td>\n",
       "      <td>1.055020</td>\n",
       "      <td>0.453897</td>\n",
       "      <td>1.055020</td>\n",
       "      <td>33.889500</td>\n",
       "      <td>169.610000</td>\n",
       "      <td>10.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.990787</td>\n",
       "      <td>1.053580</td>\n",
       "      <td>0.448678</td>\n",
       "      <td>1.053580</td>\n",
       "      <td>33.791400</td>\n",
       "      <td>170.103000</td>\n",
       "      <td>10.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>1.004731</td>\n",
       "      <td>1.059359</td>\n",
       "      <td>0.452853</td>\n",
       "      <td>1.059359</td>\n",
       "      <td>33.788400</td>\n",
       "      <td>170.118000</td>\n",
       "      <td>10.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.962823</td>\n",
       "      <td>1.084316</td>\n",
       "      <td>0.453375</td>\n",
       "      <td>1.084323</td>\n",
       "      <td>33.934300</td>\n",
       "      <td>169.386000</td>\n",
       "      <td>10.609000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.057768</td>\n",
       "      <td>1.050490</td>\n",
       "      <td>0.454593</td>\n",
       "      <td>1.050487</td>\n",
       "      <td>34.017600</td>\n",
       "      <td>168.971000</td>\n",
       "      <td>10.583000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.994321</td>\n",
       "      <td>1.067586</td>\n",
       "      <td>0.453201</td>\n",
       "      <td>1.067590</td>\n",
       "      <td>33.979900</td>\n",
       "      <td>169.159000</td>\n",
       "      <td>10.594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.981091</td>\n",
       "      <td>1.061443</td>\n",
       "      <td>0.455985</td>\n",
       "      <td>1.061440</td>\n",
       "      <td>33.996200</td>\n",
       "      <td>169.078000</td>\n",
       "      <td>10.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.984449</td>\n",
       "      <td>1.068070</td>\n",
       "      <td>0.451287</td>\n",
       "      <td>1.068068</td>\n",
       "      <td>33.887000</td>\n",
       "      <td>169.623000</td>\n",
       "      <td>10.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13900</td>\n",
       "      <td>0.968459</td>\n",
       "      <td>1.070026</td>\n",
       "      <td>0.454941</td>\n",
       "      <td>1.070023</td>\n",
       "      <td>34.085000</td>\n",
       "      <td>168.637000</td>\n",
       "      <td>10.562000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.000824</td>\n",
       "      <td>1.070174</td>\n",
       "      <td>0.456507</td>\n",
       "      <td>1.070171</td>\n",
       "      <td>33.845300</td>\n",
       "      <td>169.832000</td>\n",
       "      <td>10.637000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14100</td>\n",
       "      <td>1.025405</td>\n",
       "      <td>1.065984</td>\n",
       "      <td>0.452157</td>\n",
       "      <td>1.065982</td>\n",
       "      <td>34.060300</td>\n",
       "      <td>168.760000</td>\n",
       "      <td>10.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.981876</td>\n",
       "      <td>1.064925</td>\n",
       "      <td>0.455811</td>\n",
       "      <td>1.064930</td>\n",
       "      <td>34.084700</td>\n",
       "      <td>168.639000</td>\n",
       "      <td>10.562000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14300</td>\n",
       "      <td>0.995429</td>\n",
       "      <td>1.067301</td>\n",
       "      <td>0.451461</td>\n",
       "      <td>1.067310</td>\n",
       "      <td>33.914600</td>\n",
       "      <td>169.485000</td>\n",
       "      <td>10.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>1.067175</td>\n",
       "      <td>1.063083</td>\n",
       "      <td>0.448330</td>\n",
       "      <td>1.063081</td>\n",
       "      <td>34.131400</td>\n",
       "      <td>168.408000</td>\n",
       "      <td>10.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.969553</td>\n",
       "      <td>1.071645</td>\n",
       "      <td>0.449896</td>\n",
       "      <td>1.071648</td>\n",
       "      <td>34.342600</td>\n",
       "      <td>167.372000</td>\n",
       "      <td>10.483000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.962681</td>\n",
       "      <td>1.073872</td>\n",
       "      <td>0.444328</td>\n",
       "      <td>1.073868</td>\n",
       "      <td>33.796700</td>\n",
       "      <td>170.076000</td>\n",
       "      <td>10.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14700</td>\n",
       "      <td>1.010851</td>\n",
       "      <td>1.064476</td>\n",
       "      <td>0.449722</td>\n",
       "      <td>1.064480</td>\n",
       "      <td>34.001700</td>\n",
       "      <td>169.050000</td>\n",
       "      <td>10.588000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.964299</td>\n",
       "      <td>1.082066</td>\n",
       "      <td>0.447112</td>\n",
       "      <td>1.082066</td>\n",
       "      <td>34.133300</td>\n",
       "      <td>168.398000</td>\n",
       "      <td>10.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14900</td>\n",
       "      <td>0.929654</td>\n",
       "      <td>1.075540</td>\n",
       "      <td>0.454767</td>\n",
       "      <td>1.075543</td>\n",
       "      <td>33.945600</td>\n",
       "      <td>169.330000</td>\n",
       "      <td>10.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.955688</td>\n",
       "      <td>1.082068</td>\n",
       "      <td>0.439457</td>\n",
       "      <td>1.082063</td>\n",
       "      <td>34.095700</td>\n",
       "      <td>168.584000</td>\n",
       "      <td>10.559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15100</td>\n",
       "      <td>0.969419</td>\n",
       "      <td>1.068590</td>\n",
       "      <td>0.452679</td>\n",
       "      <td>1.068589</td>\n",
       "      <td>36.836900</td>\n",
       "      <td>156.039000</td>\n",
       "      <td>9.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.991021</td>\n",
       "      <td>1.071385</td>\n",
       "      <td>0.449896</td>\n",
       "      <td>1.071385</td>\n",
       "      <td>35.811400</td>\n",
       "      <td>160.507000</td>\n",
       "      <td>10.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15300</td>\n",
       "      <td>0.983129</td>\n",
       "      <td>1.095050</td>\n",
       "      <td>0.442067</td>\n",
       "      <td>1.095046</td>\n",
       "      <td>34.829800</td>\n",
       "      <td>165.031000</td>\n",
       "      <td>10.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.987139</td>\n",
       "      <td>1.073720</td>\n",
       "      <td>0.443981</td>\n",
       "      <td>1.073717</td>\n",
       "      <td>36.291600</td>\n",
       "      <td>158.384000</td>\n",
       "      <td>9.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.991994</td>\n",
       "      <td>1.074427</td>\n",
       "      <td>0.449722</td>\n",
       "      <td>1.074427</td>\n",
       "      <td>35.919900</td>\n",
       "      <td>160.023000</td>\n",
       "      <td>10.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.945263</td>\n",
       "      <td>1.067937</td>\n",
       "      <td>0.453549</td>\n",
       "      <td>1.067939</td>\n",
       "      <td>36.854400</td>\n",
       "      <td>155.965000</td>\n",
       "      <td>9.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15700</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>1.074556</td>\n",
       "      <td>0.450939</td>\n",
       "      <td>1.074555</td>\n",
       "      <td>37.009300</td>\n",
       "      <td>155.312000</td>\n",
       "      <td>9.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>1.004450</td>\n",
       "      <td>1.064107</td>\n",
       "      <td>0.454593</td>\n",
       "      <td>1.064109</td>\n",
       "      <td>35.071800</td>\n",
       "      <td>163.893000</td>\n",
       "      <td>10.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15900</td>\n",
       "      <td>1.004924</td>\n",
       "      <td>1.067878</td>\n",
       "      <td>0.452679</td>\n",
       "      <td>1.067875</td>\n",
       "      <td>34.821100</td>\n",
       "      <td>165.073000</td>\n",
       "      <td>10.339000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.010222</td>\n",
       "      <td>1.061872</td>\n",
       "      <td>0.449374</td>\n",
       "      <td>1.061871</td>\n",
       "      <td>34.849600</td>\n",
       "      <td>164.937000</td>\n",
       "      <td>10.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16100</td>\n",
       "      <td>0.926600</td>\n",
       "      <td>1.079981</td>\n",
       "      <td>0.454593</td>\n",
       "      <td>1.079984</td>\n",
       "      <td>34.868200</td>\n",
       "      <td>164.850000</td>\n",
       "      <td>10.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>0.977207</td>\n",
       "      <td>1.075626</td>\n",
       "      <td>0.456681</td>\n",
       "      <td>1.075629</td>\n",
       "      <td>35.104700</td>\n",
       "      <td>163.739000</td>\n",
       "      <td>10.255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16300</td>\n",
       "      <td>1.020930</td>\n",
       "      <td>1.072991</td>\n",
       "      <td>0.452853</td>\n",
       "      <td>1.072997</td>\n",
       "      <td>34.845600</td>\n",
       "      <td>164.956000</td>\n",
       "      <td>10.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>1.014022</td>\n",
       "      <td>1.063125</td>\n",
       "      <td>0.448330</td>\n",
       "      <td>1.063124</td>\n",
       "      <td>34.853900</td>\n",
       "      <td>164.917000</td>\n",
       "      <td>10.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.951401</td>\n",
       "      <td>1.071648</td>\n",
       "      <td>0.453897</td>\n",
       "      <td>1.071643</td>\n",
       "      <td>34.836100</td>\n",
       "      <td>165.001000</td>\n",
       "      <td>10.334000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>0.977358</td>\n",
       "      <td>1.076179</td>\n",
       "      <td>0.453027</td>\n",
       "      <td>1.076179</td>\n",
       "      <td>35.083100</td>\n",
       "      <td>163.840000</td>\n",
       "      <td>10.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16700</td>\n",
       "      <td>1.041526</td>\n",
       "      <td>1.088078</td>\n",
       "      <td>0.439109</td>\n",
       "      <td>1.088078</td>\n",
       "      <td>34.901900</td>\n",
       "      <td>164.690000</td>\n",
       "      <td>10.315000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.988475</td>\n",
       "      <td>1.065809</td>\n",
       "      <td>0.449896</td>\n",
       "      <td>1.065805</td>\n",
       "      <td>34.962000</td>\n",
       "      <td>164.407000</td>\n",
       "      <td>10.297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16900</td>\n",
       "      <td>1.007113</td>\n",
       "      <td>1.068755</td>\n",
       "      <td>0.447112</td>\n",
       "      <td>1.068756</td>\n",
       "      <td>34.819100</td>\n",
       "      <td>165.082000</td>\n",
       "      <td>10.339000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.975641</td>\n",
       "      <td>1.068735</td>\n",
       "      <td>0.450418</td>\n",
       "      <td>1.068724</td>\n",
       "      <td>34.775700</td>\n",
       "      <td>165.288000</td>\n",
       "      <td>10.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17100</td>\n",
       "      <td>0.954986</td>\n",
       "      <td>1.069831</td>\n",
       "      <td>0.456159</td>\n",
       "      <td>1.069834</td>\n",
       "      <td>34.894900</td>\n",
       "      <td>164.723000</td>\n",
       "      <td>10.317000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>0.955351</td>\n",
       "      <td>1.074576</td>\n",
       "      <td>0.450765</td>\n",
       "      <td>1.074581</td>\n",
       "      <td>35.341200</td>\n",
       "      <td>162.643000</td>\n",
       "      <td>10.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17300</td>\n",
       "      <td>1.009158</td>\n",
       "      <td>1.079706</td>\n",
       "      <td>0.444328</td>\n",
       "      <td>1.079717</td>\n",
       "      <td>35.505800</td>\n",
       "      <td>161.889000</td>\n",
       "      <td>10.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>0.980130</td>\n",
       "      <td>1.070807</td>\n",
       "      <td>0.451809</td>\n",
       "      <td>1.070810</td>\n",
       "      <td>36.553900</td>\n",
       "      <td>157.247000</td>\n",
       "      <td>9.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.984357</td>\n",
       "      <td>1.072790</td>\n",
       "      <td>0.453549</td>\n",
       "      <td>1.072789</td>\n",
       "      <td>36.631800</td>\n",
       "      <td>156.913000</td>\n",
       "      <td>9.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>0.990831</td>\n",
       "      <td>1.068632</td>\n",
       "      <td>0.453027</td>\n",
       "      <td>1.068631</td>\n",
       "      <td>36.795800</td>\n",
       "      <td>156.213000</td>\n",
       "      <td>9.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17700</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>1.070293</td>\n",
       "      <td>0.453375</td>\n",
       "      <td>1.070297</td>\n",
       "      <td>37.039400</td>\n",
       "      <td>155.186000</td>\n",
       "      <td>9.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>1.073751</td>\n",
       "      <td>0.449722</td>\n",
       "      <td>1.073758</td>\n",
       "      <td>34.721700</td>\n",
       "      <td>165.545000</td>\n",
       "      <td>10.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17900</td>\n",
       "      <td>1.000144</td>\n",
       "      <td>1.071557</td>\n",
       "      <td>0.455289</td>\n",
       "      <td>1.071558</td>\n",
       "      <td>34.379600</td>\n",
       "      <td>167.192000</td>\n",
       "      <td>10.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.989411</td>\n",
       "      <td>1.069449</td>\n",
       "      <td>0.452331</td>\n",
       "      <td>1.069451</td>\n",
       "      <td>34.452100</td>\n",
       "      <td>166.840000</td>\n",
       "      <td>10.449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18100</td>\n",
       "      <td>1.008904</td>\n",
       "      <td>1.069830</td>\n",
       "      <td>0.451983</td>\n",
       "      <td>1.069825</td>\n",
       "      <td>34.695000</td>\n",
       "      <td>165.672000</td>\n",
       "      <td>10.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18200</td>\n",
       "      <td>1.028364</td>\n",
       "      <td>1.066773</td>\n",
       "      <td>0.454419</td>\n",
       "      <td>1.066774</td>\n",
       "      <td>34.200200</td>\n",
       "      <td>168.069000</td>\n",
       "      <td>10.526000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18300</td>\n",
       "      <td>0.975403</td>\n",
       "      <td>1.067470</td>\n",
       "      <td>0.455289</td>\n",
       "      <td>1.067470</td>\n",
       "      <td>34.163000</td>\n",
       "      <td>168.252000</td>\n",
       "      <td>10.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>0.981240</td>\n",
       "      <td>1.068406</td>\n",
       "      <td>0.454767</td>\n",
       "      <td>1.068404</td>\n",
       "      <td>34.033400</td>\n",
       "      <td>168.893000</td>\n",
       "      <td>10.578000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.981033</td>\n",
       "      <td>1.066940</td>\n",
       "      <td>0.456159</td>\n",
       "      <td>1.066941</td>\n",
       "      <td>34.202800</td>\n",
       "      <td>168.056000</td>\n",
       "      <td>10.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18600</td>\n",
       "      <td>0.975419</td>\n",
       "      <td>1.067660</td>\n",
       "      <td>0.454071</td>\n",
       "      <td>1.067664</td>\n",
       "      <td>34.252400</td>\n",
       "      <td>167.813000</td>\n",
       "      <td>10.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18700</td>\n",
       "      <td>0.958525</td>\n",
       "      <td>1.070158</td>\n",
       "      <td>0.452679</td>\n",
       "      <td>1.070157</td>\n",
       "      <td>34.093500</td>\n",
       "      <td>168.595000</td>\n",
       "      <td>10.559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>0.996336</td>\n",
       "      <td>1.068995</td>\n",
       "      <td>0.451809</td>\n",
       "      <td>1.068999</td>\n",
       "      <td>34.162100</td>\n",
       "      <td>168.257000</td>\n",
       "      <td>10.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18900</td>\n",
       "      <td>0.960458</td>\n",
       "      <td>1.069511</td>\n",
       "      <td>0.452505</td>\n",
       "      <td>1.069507</td>\n",
       "      <td>34.165000</td>\n",
       "      <td>168.242000</td>\n",
       "      <td>10.537000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.990687</td>\n",
       "      <td>1.069015</td>\n",
       "      <td>0.453897</td>\n",
       "      <td>1.069016</td>\n",
       "      <td>34.251400</td>\n",
       "      <td>167.818000</td>\n",
       "      <td>10.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19100</td>\n",
       "      <td>0.964402</td>\n",
       "      <td>1.069610</td>\n",
       "      <td>0.453375</td>\n",
       "      <td>1.069608</td>\n",
       "      <td>34.175800</td>\n",
       "      <td>168.189000</td>\n",
       "      <td>10.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>1.010162</td>\n",
       "      <td>1.068939</td>\n",
       "      <td>0.455289</td>\n",
       "      <td>1.068938</td>\n",
       "      <td>34.086100</td>\n",
       "      <td>168.632000</td>\n",
       "      <td>10.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19300</td>\n",
       "      <td>0.974866</td>\n",
       "      <td>1.068331</td>\n",
       "      <td>0.455115</td>\n",
       "      <td>1.068330</td>\n",
       "      <td>34.061200</td>\n",
       "      <td>168.755000</td>\n",
       "      <td>10.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19400</td>\n",
       "      <td>0.952997</td>\n",
       "      <td>1.068429</td>\n",
       "      <td>0.454941</td>\n",
       "      <td>1.068429</td>\n",
       "      <td>34.125700</td>\n",
       "      <td>168.436000</td>\n",
       "      <td>10.549000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.11it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.63it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.00it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.71it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.33it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.37it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.71it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.50it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.76it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.03it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.16it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.53it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.19it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.43it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.88it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.56it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.52it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.49it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.36it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.11it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.53it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.27it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.51it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.38it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.49it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.34it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.91it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.12it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.65it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.96it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.85it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.40it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.44it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.49it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.54it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.45it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.46it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.62it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.62it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.24it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.61it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.46it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.55it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.10it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.60it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.29it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.36it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.66it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.24it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.41it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.38it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.01it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.30it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.41it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.86it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.87it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.27it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.03it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.21it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.31it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.93it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.48it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.91it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.29it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.57it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.38it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.52it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.43it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.44it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.56it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.45it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.10it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.45it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.38it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.02it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.52it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.70it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.19it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.56it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.87it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.10it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.13it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.32it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.27it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.68it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  3.13it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.24it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.26it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.26it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.33it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.35it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.14it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.37it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.51it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  4.31it/s]\n",
      "Writing model shards: 100%|| 1/1 [00:00<00:00,  2.72it/s]\n",
      "There were missing keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias'].\n",
      "There were unexpected keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.beta', 'distilbert.embeddings.LayerNorm.gamma'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=19401, training_loss=1.0392737645450607, metrics={'train_runtime': 10798.6124, 'train_samples_per_second': 14.371, 'train_steps_per_second': 1.797, 'total_flos': 2.055758480403149e+16, 'train_loss': 1.0392737645450607, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ").to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "\n",
    "    # GPU parameters\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=1,\n",
    "    fp16=True,\n",
    "\n",
    "    # training epochs\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    # optimizer parameters\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "\n",
    "    # evaluation&save parameters\n",
    "    eval_strategy=\"steps\", # or \"epoch\"\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    # logging&report parameters\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    # gradient_checkpointing=True # enable gradient checkpointing\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_enc,\n",
    "    eval_dataset=val_enc,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # callbacks=[transformers.EarlyStoppingCallback(early_stopping_patience=3)] # enable early stopping\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e45a1b",
   "metadata": {},
   "source": [
    "## 6. Validation Evaluation and Test Prediction\n",
    "\n",
    "1. Evaluate on the validation set and report accuracy and log_loss.\n",
    "2. Predict on the test set and generate `submission.csv` with:\n",
    "   - `id`\n",
    "   - `winner_model_a`, `winner_model_b`, `winner_tie` (predicted probabilities for each class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c7a7c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "{'eval_loss': 1.0436153411865234, 'eval_accuracy': 0.4596381350034795, 'eval_log_loss': 1.0436119474286631, 'eval_runtime': 33.8308, 'eval_samples_per_second': 169.904, 'eval_steps_per_second': 10.641, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation results:\")\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e40041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.343558</td>\n",
       "      <td>0.247909</td>\n",
       "      <td>0.408533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.442657</td>\n",
       "      <td>0.289152</td>\n",
       "      <td>0.268190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.356988</td>\n",
       "      <td>0.342407</td>\n",
       "      <td>0.300605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060        0.343558        0.247909    0.408533\n",
       "1   211333        0.442657        0.289152    0.268190\n",
       "2  1233961        0.356988        0.342407    0.300605"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_enc)\n",
    "probs = torch.softmax(torch.tensor(predictions.predictions), dim=-1).numpy()\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": df_test[\"id\"],\n",
    "    \"winner_model_a\": probs[:, 0],\n",
    "    \"winner_model_b\": probs[:, 1],\n",
    "    \"winner_tie\": probs[:, 2],\n",
    "})\n",
    "\n",
    "submission_path = \"submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"Submission file saved to {submission_path}\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7507a9",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "- How to load and visualize Kaggle LLM Classification Finetuning `train.csv` / `test.csv` data\n",
    "- How to combine three text fields (prompt, response_a, response_b) into one model input\n",
    "- How to fine-tune a 3-class DistilBERT model with cross-entropy loss\n",
    "- How to evaluate on the validation set (accuracy, log_loss)\n",
    "- How to predict the test set and generate a submission file in the required format\n",
    "\n",
    "You can extend this by:\n",
    "\n",
    "- Trying a larger model or incorporating `model_a`/`model_b` as features\n",
    "- Improving the input construction (e.g., encode A/B separately then compare)\n",
    "- Adding richer visualizations and error analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
